import asyncio
import json
import time
from pathlib import Path
from typing import Dict, Any, List

from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI

from bot.config import OPENAI_API_KEY, OPENAI_MODEL, LOGS_DIR

# ==============================
#  INIT
# ==============================

client = OpenAI(api_key=OPENAI_API_KEY)
executor = ThreadPoolExecutor()

Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)


# ==============================
#  SESSION MANAGER
# ==============================

class SessionManager:
    def __init__(self):
        self.sessions: Dict[int, Dict[str, Any]] = {}

    def get(self, user_id: int) -> Dict[str, Any]:
        return self.sessions.setdefault(user_id, {"history": [], "last_active": time.time()})

    def append_history(self, user_id: int, role: str, content: str):
        entry = {"role": role, "content": content, "ts": time.time()}
        s = self.get(user_id)
        s["history"].append(entry)
        self._write_log(user_id, entry)

    def get_messages(self, user_id: int):
        s = self.get(user_id)
        # OpenAI chat API –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ {role, content}
        return [{"role": m["role"], "content": m["content"]} for m in s["history"]]

    def _write_log(self, user_id: int, entry: dict):
        path = Path(LOGS_DIR) / f"{user_id}.json"
        try:
            if path.exists():
                data = json.loads(path.read_text(encoding="utf-8"))
            else:
                data = []
        except:
            data = []

        data.append(entry)
        path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


sessions = SessionManager()


# ==============================
#  LOAD JSON DATABASES
# ==============================

BASE_PATH = Path("ai_responder/data")

try:
    navigation_data = json.loads((BASE_PATH / "navigation.json").read_text(encoding="utf-8"))
except:
    navigation_data = {}

try:
    rules_data = json.loads((BASE_PATH / "rules.json").read_text(encoding="utf-8"))
except:
    rules_data = []


# ==============================
#  KNOWLEDGE SEARCH
# ==============================

def normalize(text: str):
    return text.lower().strip()


def collect_relevant_knowledge(user_question: str) -> List[Dict[str, Any]]:
    user_question = normalize(user_question)
    results = []

    # NAVIGATION
    for name, entry in navigation_data.items():
        for kw in entry.get("keywords", []):
            if normalize(kw) in user_question:
                results.append({
                    "type": "navigation",
                    "name": name,
                    "hint": entry.get("hint", "")
                })
                break

    # RULES
    for rule in rules_data:
        if not isinstance(rule, dict):
            continue
        for kw in rule.get("keywords", []):
            if normalize(kw) in user_question:
                results.append({
                    "type": "rule",
                    "answer": rule.get("answer", "")
                })
                break

    return results


# ==============================
#  HUMANIZED RESPONSES
# ==============================

def build_response(knowledge: List[Dict[str, Any]], question: str) -> str:
    if not knowledge:
        return (
            "‚õî –°–µ–π—á–∞—Å –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. "
            "–ï—Å–ª–∏ —É—Ç–æ—á–Ω–∏—à—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî —è –ø–æ–º–æ–≥—É."
        )

    parts = []

    for item in knowledge:
        if item["type"] == "navigation":
            parts.append(
                f"üîπ <b>{item['name'].capitalize()}</b>\n"
                f"{item['hint']}"
            )
        elif item["type"] == "rule":
            parts.append(item["answer"])

    return "\n\n".join(parts)


# ==============================
#  OPENAI CALL (–°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ –° HEROKU)
# ==============================

def _sync_chat_call(messages):
    """–°—Ç–∞–±–∏–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Heroku"""
    response = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=1,
    )

    # –í—Å–µ–≥–¥–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–æ—Å—Ç–∞—ë–º —Ç–µ–∫—Å—Ç
    return response.choices[0].message["content"]


# ==============================
#  MAIN RESPONSE LOGIC
# ==============================

async def ask_ai(user_id: int, question: str):
    # –ü–æ–∏—Å–∫ –≤ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏/–ø—Ä–∞–≤–∏–ª–∞—Ö
    knowledge = collect_relevant_knowledge(question)
    base_answer = build_response(knowledge, question)

    system_prompt = (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∞–∑–∏–Ω–æ –∏ –±–µ—Ç—Ç–∏–Ω–≥–∞. "
        "–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç—ã–º –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º, –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏. "
        "–û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—é, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã—Ö. "
        "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî –ø–æ–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–∏—Ç—å."
    )

    msgs = [{"role": "system", "content": system_prompt}]
    msgs += sessions.get_messages(user_id)
    msgs.append({
        "role": "user",
        "content": f"–í–æ–ø—Ä–æ—Å: {question}\n–î–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã: {base_answer}"
    })

    loop = asyncio.get_running_loop()
    try:
        ai_answer = await loop.run_in_executor(executor, _sync_chat_call, msgs)
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"

    # –õ–æ–≥–∏—Ä—É–µ–º
    sessions.append_history(user_id, "user", question)
    sessions.append_history(user_id, "assistant", ai_answer)

    return ai_answer
