import asyncio
import json
import time
from pathlib import Path
from typing import Dict, Any, List

from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI

from bot.config import OPENAI_API_KEY, OPENAI_MODEL, LOGS_DIR

# ==============================
#  INIT
# ==============================

client = OpenAI(api_key=OPENAI_API_KEY)
executor = ThreadPoolExecutor()

Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)


# ==============================
#  SESSION MANAGER
# ==============================

class SessionManager:
    def __init__(self):
        self.sessions: Dict[int, Dict[str, Any]] = {}

    def get(self, user_id: int) -> Dict[str, Any]:
        return self.sessions.setdefault(user_id, {"history": [], "last_active": time.time()})

    def append_history(self, user_id: int, role: str, content: str):
        entry = {"role": role, "content": content, "ts": time.time()}
        s = self.get(user_id)
        s["history"].append(entry)
        self._write_log(user_id, entry)

    def get_messages(self, user_id: int):
        s = self.get(user_id)
        return [{"role": m["role"], "content": m["content"]} for m in s["history"]]

    def _write_log(self, user_id: int, entry: dict):
        path = Path(LOGS_DIR) / f"{user_id}.json"
        try:
            if path.exists():
                data = json.loads(path.read_text(encoding="utf-8"))
            else:
                data = []
        except:
            data = []

        data.append(entry)
        path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


sessions = SessionManager()


# ==============================
#  LOAD JSON DATABASES
# ==============================

BASE_PATH = Path("ai_responder/data")

try:
    navigation_data = json.loads((BASE_PATH / "navigation.json").read_text(encoding="utf-8"))
except:
    navigation_data = {}

try:
    rules_data = json.loads((BASE_PATH / "rules.json").read_text(encoding="utf-8"))
except:
    rules_data = []


# ==============================
#  KNOWLEDGE SEARCH
# ==============================

def normalize(text: str):
    return text.lower().strip()


def collect_relevant_knowledge(user_question: str) -> List[Dict[str, Any]]:
    user_question = normalize(user_question)
    results = []

    # -------- NAVIGATION --------
    for name, entry in navigation_data.items():
        keywords = entry.get("keywords", [])
        for kw in keywords:
            if normalize(kw) in user_question:
                results.append({
                    "type": "navigation",
                    "name": name,
                    "hint": entry.get("hint", "")
                })
                break

    # -------- RULES --------
    for rule in rules_data:
        if not isinstance(rule, dict):
            continue

        keywords = rule.get("keywords", [])
        for kw in keywords:
            if normalize(kw) in user_question:
                results.append({
                    "type": "rule",
                    "answer": rule.get("answer", "")
                })
                break

    return results


# ==============================
#  HUMANIZED RESPONSE BUILDER
# ==============================

def build_response(knowledge: List[Dict[str, Any]], question: str) -> str:
    if not knowledge:
        return (
            "–ü–æ–∫–∞ –Ω–µ –≤–∏–∂—É —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –ø—Ä–∞–≤–∏–ª–∞—Ö –∏–ª–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏. "
            "–ù–æ —è —Ä—è–¥–æ–º ‚Äî —É—Ç–æ—á–Ω–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ö–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å."
        )

    parts = []

    for item in knowledge:
        if item["type"] == "navigation":
            parts.append(
                f"üîπ *{item['name'].capitalize()}*\n"
                f"{item['hint']}"
            )
        elif item["type"] == "rule":
            parts.append(item["answer"])

    return "\n\n".join(parts)


# ==============================
#  OPENAI CALL (–ù–û–í–ê–Ø API 2025)
# ==============================

def _sync_chat_call(messages):
    """
    –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: –Ω–æ–≤–∞—è OpenAI Responses API
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ resp.output[0].content[0].text
    """
    resp = client.responses.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=1,
    )

    try:
        return resp.output[0].content[0].text
    except Exception:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."


# ==============================
#  MAIN LOGIC
# ==============================

async def ask_ai(user_id: int, question: str):
    # –ò—â–µ–º –ø–æ –±–∞–∑–µ
    knowledge = collect_relevant_knowledge(question)
    base_answer = build_response(knowledge, question)

    # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    system_prompt = (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ–¥–¥–µ—Ä–∂–∫–∏. "
        "–û—Ç–≤–µ—á–∞–π –≤–Ω—è—Ç–Ω–æ, —Å–ø–æ–∫–æ–π–Ω–æ, –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏. "
        "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã. "
        "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å—Ç—å –≤ –±–∞–∑–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ—ë. "
        "–ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –º—è–≥–∫–æ –ø–æ–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–∏—Ç—å –≤–æ–ø—Ä–æ—Å."
    )

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
    msgs = [{"role": "system", "content": system_prompt}]
    msgs += sessions.get_messages(user_id)
    msgs.append({"role": "user", "content": f"–í–æ–ø—Ä–æ—Å: {question}\n–î–∞–Ω–Ω—ã–µ: {base_answer}"})

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI (—á–µ—Ä–µ–∑ executor)
    loop = asyncio.get_running_loop()
    try:
        ai_answer = await loop.run_in_executor(executor, _sync_chat_call, msgs)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    sessions.append_history(user_id, "user", question)
    sessions.append_history(user_id, "assistant", ai_answer)

    return ai_answer
