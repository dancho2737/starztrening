import asyncio
import json
import time
from pathlib import Path
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor

from openai import OpenAI
from bot.config import OPENAI_API_KEY, OPENAI_MODEL, LOGS_DIR


# ==============================
#  INIT
# ==============================

client = OpenAI(api_key=OPENAI_API_KEY)
executor = ThreadPoolExecutor()

Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)


# ==============================
#  SESSION MANAGER
# ==============================

class SessionManager:
    def __init__(self):
        self.sessions: Dict[int, Dict[str, Any]] = {}

    def get(self, user_id: int) -> Dict[str, Any]:
        return self.sessions.setdefault(user_id, {"history": [], "last_active": time.time()})

    def append_history(self, user_id: int, role: str, content: str):
        entry = {"role": role, "content": content, "ts": time.time()}
        s = self.get(user_id)
        s["history"].append(entry)
        self._write_log(user_id, entry)

    def get_messages(self, user_id: int):
        s = self.get(user_id)
        return [{"role": m["role"], "content": m["content"]} for m in s["history"]]

    def _write_log(self, user_id: int, entry: dict):
        path = Path(LOGS_DIR) / f"{user_id}.json"
        try:
            data = json.loads(path.read_text(encoding="utf-8")) if path.exists() else []
        except:
            data = []

        data.append(entry)
        path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


sessions = SessionManager()


# ==============================
#  LOAD JSON DATABASES
# ==============================

BASE_PATH = Path("ai_responder/data")

try:
    navigation_data = json.loads((BASE_PATH / "navigation.json").read_text(encoding="utf-8"))
except:
    navigation_data = {}

try:
    rules_data = json.loads((BASE_PATH / "rules.json").read_text(encoding="utf-8"))
except:
    rules_data = []


# ==============================
#  KNOWLEDGE SEARCH
# ==============================

def normalize(text: str):
    return text.lower().strip()


def collect_relevant_knowledge(user_question: str) -> List[Dict[str, Any]]:
    user_question = normalize(user_question)
    results = []

    # NAVIGATION ‚Äî —Å–ª–æ–≤–∞—Ä—å
    for name, entry in navigation_data.items():
        for kw in entry.get("keywords", []):
            if normalize(kw) in user_question:
                results.append({
                    "type": "navigation",
                    "name": name,
                    "hint": entry.get("hint", "")
                })
                break

    # RULES
    for rule in rules_data:
        if not isinstance(rule, dict):
            continue
        for kw in rule.get("keywords", []):
            if normalize(kw) in user_question:
                results.append({
                    "type": "rule",
                    "answer": rule.get("answer", "")
                })
                break

    return results


# ==============================
#  HUMANIZED RESPONSE BUILDER
# ==============================

def build_response(knowledge: List[Dict[str, Any]], question: str) -> str:
    if not knowledge:
        return (
            "‚õî –°–µ–π—á–∞—Å –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. "
            "–ï—Å–ª–∏ —É—Ç–æ—á–Ω–∏—à—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî —è –ø–æ–º–æ–≥—É."
        )

    parts = []

    for item in knowledge:
        if item["type"] == "navigation":
            parts.append(
                f"üîπ <b>{item['name'].capitalize()}</b>\n"
                f"{item['hint']}"
            )
        elif item["type"] == "rule":
            parts.append(item["answer"])

    return "\n\n".join(parts)


# ==============================
#  OPENAI CHAT API ‚Äî –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô
# ==============================

def _sync_chat_call(messages):
    """
    –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ openai>=1.59.0.
    –û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ä–µ–∫—Ç, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å.
    """
    response = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=1,
    )

    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
    return response.choices[0].message.content


# ==============================
#  MAIN RESPONSE LOGIC
# ==============================

async def ask_ai(user_id: int, question: str):
    knowledge = collect_relevant_knowledge(question)
    base_answer = build_response(knowledge, question)

    system_prompt = (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∞–∑–∏–Ω–æ –∏ –±–µ—Ç—Ç–∏–Ω–≥–∞. "
        "–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç—ã–º –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º. "
        "–û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã–µ –±–∞–∑—ã. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω–∏—Ç—å."
    )

    msgs = [{"role": "system", "content": system_prompt}]
    msgs += sessions.get_messages(user_id)
    msgs.append({"role": "user", "content": f"–í–æ–ø—Ä–æ—Å: {question}\n–î–∞–Ω–Ω—ã–µ: {base_answer}"})

    loop = asyncio.get_running_loop()
    try:
        ai_answer = await loop.run_in_executor(executor, _sync_chat_call, msgs)
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"

    sessions.append_history(user_id, "user", question)
    sessions.append_history(user_id, "assistant", ai_answer)

    return ai_answer
