# ai_responder/responder.py
import json
import re
import difflib
import math
from pathlib import Path
from typing import List, Dict, Optional, Any
from openai import OpenAI
from bot.config import OPENAI_API_KEY, OPENAI_MODEL

ROOT = Path(__file__).resolve().parents[1]

# пути к данным
PATH_NAV_DESKTOP = ROOT / "data" / "navigation.json"
PATH_NAV_MOBILE = ROOT / "data" / "navigation_mobile.json"
PATH_RULES = ROOT / "data" / "rules.json"
PATH_PROMPT = ROOT / "prompts" / "system_prompt.txt"

# debug флаг (включи для логов ранжирования)
DEBUG_RANKING = False

# загрузка json безопасно
def load_json(p: Path):
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return []

navigation_desktop = load_json(PATH_NAV_DESKTOP)
navigation_mobile = load_json(PATH_NAV_MOBILE)
rules = load_json(PATH_RULES)

if DEBUG_RANKING:
    print("DEBUG: navigation_desktop len =", len(navigation_desktop))
    print("DEBUG: navigation_mobile len =", len(navigation_mobile))
    print("DEBUG: rules len =", len(rules))
    if navigation_desktop:
        print("DEBUG nav[0] keys:", list(navigation_desktop[0].keys()))
    if rules:
        print("DEBUG rule[0] keys:", list(rules[0].keys()))

try:
    SYSTEM_PROMPT = PATH_PROMPT.read_text(encoding="utf-8")
except Exception:
    SYSTEM_PROMPT = "Ты — оператор поддержки. Отвечай строго по базе."

# OpenAI клиент (опционально)
try:
    openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
except Exception:
    openai_client = None


# Сессии
class SessionStore:
    def __init__(self):
        self.history: Dict[int, List[Dict]] = {}
        self.device: Dict[int, str] = {}           # "mobile" / "desktop"
        self.pending: Dict[int, List[Dict]] = {}   # user_id -> list of options
        self.first_seen: set = set()

    def add_history(self, user_id: int, role: str, content: str):
        self.history.setdefault(user_id, []).append({"role": role, "content": content})

    def get_history(self, user_id: int):
        return self.history.get(user_id, [])

    def add(self, user_id: int, role: str, content: str):
        return self.add_history(user_id, role, content)

    def get(self, user_id: int):
        return self.get_history(user_id)

    def clear(self, user_id: int):
        self.history.pop(user_id, None)
        self.pending.pop(user_id, None)
        self.device.pop(user_id, None)
        self.first_seen.discard(user_id)

    def set_device(self, user_id: int, device: str):
        if device in ("mobile", "desktop"):
            self.device[user_id] = device

    def get_device(self, user_id: int) -> Optional[str]:
        return self.device.get(user_id)

    def has_device(self, user_id: int) -> bool:
        return user_id in self.device

    def set_pending(self, user_id: int, options: List[Dict]):
        self.pending[user_id] = options

    def get_pending(self, user_id: int) -> Optional[List[Dict]]:
        return self.pending.get(user_id)

    def clear_pending(self, user_id: int):
        self.pending.pop(user_id, None)

    def mark_seen(self, user_id: int):
        self.first_seen.add(user_id)

    def was_seen(self, user_id: int) -> bool:
        return user_id in self.first_seen


sessions = SessionStore()

user_device: Dict[int, str] = {}

def _sync_user_device_from_sessions():
    for uid, dev in sessions.device.items():
        user_device[uid] = dev

_sync_user_device_from_sessions()


def _title_of(item: Dict, default: str) -> str:
    t = item.get("title") or item.get("name")
    if not t:
        kws = item.get("keywords") or []
        if kws:
            t = kws[0]
    if not t:
        txt = ""
        if isinstance(item.get("answer"), str):
            txt = item.get("answer")
        elif isinstance(item.get("answer"), dict):
            txt = item.get("answer").get("title", "") or item.get("answer").get("steps", [""])[0]
        else:
            txt = item.get("hint") or ""
        t = (txt[:60] + "...") if txt else default
    return t


# семантические хелперы
def _cosine(a: List[float], b: List[float]) -> float:
    if not a or not b:
        return 0.0
    dot = sum(x * y for x, y in zip(a, b))
    na = math.sqrt(sum(x * x for x in a))
    nb = math.sqrt(sum(y * y for y in b))
    if na == 0 or nb == 0:
        return 0.0
    return dot / (na * nb)


def _collect_candidates(device: str) -> List[Dict]:
    nav = navigation_mobile if device == "mobile" else navigation_desktop
    items: List[Dict] = []
    for item in nav:
        items.append({
            "type": "navigation",
            "title": _title_of(item, "Навигация"),
            "keywords": item.get("keywords", []),
            "value": item.get("answer") if item.get("answer") is not None else item.get("hint", ""),
            "_raw": item
        })
    for rule in rules:
        if not isinstance(rule, dict):
            continue
        items.append({
            "type": "rules",
            "title": _title_of(rule, "Правило"),
            "keywords": rule.get("keywords", []),
            "value": rule.get("answer") if rule.get("answer") is not None else rule.get("hint", ""),
            "_raw": rule
        })
    return items


def _semantic_match_with_embeddings(question: str, device: str, top_k: int = 3) -> List[Dict]:
    if not openai_client:
        return []
    try:
        items = _collect_candidates(device)
        if not items:
            return []
        texts = []
        for it in items:
            kws = " ".join(it.get("keywords") or [])
            snippet = (it.get("value") or "")[:600]
            texts.append(f"{it.get('title','')}. {kws}. {snippet}")
        emb_model = "text-embedding-3-small"
        resp = openai_client.embeddings.create(model=emb_model, input=[question] + texts)
        if not resp or not getattr(resp, "data", None):
            return []
        all_emb = [d.embedding for d in resp.data]
        q_emb = all_emb[0]
        item_embs = all_emb[1:]
        sims = []
        for i, emb in enumerate(item_embs):
            sim = _cosine(q_emb, emb)
            sims.append((i, sim))
        sims.sort(key=lambda x: x[1], reverse=True)
        results = []
        for idx, sim in sims[:top_k]:
            if sim < 0.5:
                continue
            it = items[idx]
            results.append({
                "type": it["type"],
                "title": it["title"],
                "value": it["value"],
                "score": sim,
                "_raw": it["_raw"]
            })
        return results
    except Exception:
        return []


def _semantic_match_with_chat(question: str, device: str, top_k: int = 3) -> List[Dict]:
    if not openai_client:
        return []
    try:
        items = _collect_candidates(device)
        if not items:
            return []
        max_list = 30
        short_items = items[:max_list]
        numbered = []
        for i, it in enumerate(short_items, start=1):
            kws = ", ".join(it.get("keywords") or [])
            snippet = (it.get("value") or "")[:300]
            numbered.append(f"{i}. {it['title']} | keywords: {kws} | snippet: {snippet}")
        system = (
            "Ты — помощник, задача которого — по вопросу пользователя выбрать наиболее релевантные элементы "
            "из списка. Верни JSON-массив индексов (1-основной индекс в списке ниже) в порядке убывания релевантности. "
            "Если ничего подходящего нет, верни пустой массив []. Отвечай только JSON, например: [2,5]"
        )
        user = f"Вопрос: {question}\n\nСписок элементов:\n" + "\n".join(numbered) + "\n\nВерни JSON-массив индексов."
        resp = openai_client.chat.completions.create(
            model=OPENAI_MODEL or "gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ],
            temperature=0.0,
            max_tokens=300,
        )
        if not resp or not getattr(resp, "choices", None):
            return []
        text = None
        choice0 = resp.choices[0]
        if hasattr(choice0, "message") and isinstance(choice0.message, dict):
            text = choice0.message.get("content")
        elif hasattr(choice0, "message") and hasattr(choice0.message, "get"):
            text = choice0.message.get("content")
        elif hasattr(choice0, "text"):
            text = choice0.text
        if not text:
            return []
        import re as _re
        m = _re.search(r"(\[.*\])", text, re.S)
        arr_txt = m.group(1) if m else text.strip()
        try:
            idxs = json.loads(arr_txt)
            if not isinstance(idxs, list):
                return []
        except Exception:
            nums = re.findall(r"\d+", text)
            idxs = [int(x) for x in nums[:top_k]]
        results = []
        for n in idxs[:top_k]:
            if 1 <= n <= len(short_items):
                it = short_items[n - 1]
                results.append({
                    "type": it["type"],
                    "title": it["title"],
                    "value": it["value"],
                    "_raw": it["_raw"]
                })
        return results
    except Exception:
        return []


# вспомогательные скоринг-функции
def _token_overlap_score(q1: str, q2: str) -> float:
    t1 = set(re.findall(r'\w+', (q1 or "").lower()))
    t2 = set(re.findall(r'\w+', (q2 or "").lower()))
    if not t1 or not t2:
        return 0.0
    return len(t1 & t2) / max(len(t1), len(t2))


def _score_for_keyword_match(q: str, kw: str) -> float:
    if not kw:
        return 0.0
    kw_clean = re.sub(r'\s+', ' ', (kw or "").lower().strip())
    if q == kw_clean:
        return 1.0
    if kw_clean in q:
        return 0.90
    overlap = _token_overlap_score(q, kw_clean)
    if overlap > 0:
        return max(0.0, min(0.85, overlap * 0.85))
    try:
        ratio = difflib.SequenceMatcher(None, q, kw_clean).ratio()
        if ratio > 0.6:
            return (ratio - 0.6) / 0.4 * 0.45 + 0.45
    except Exception:
        pass
    return 0.0


# улучшённый search_matches с приоритетом navigation и steps
def search_matches(question: str, device: str) -> List[Dict]:
    q_raw = (question or "").strip()
    q = re.sub(r'\s+', ' ', q_raw.lower())

    nav = navigation_mobile if device == "mobile" else navigation_desktop
    candidates = []

    def add_candidate(item: Dict, item_type: str):
        # answer приоритетнее hint (workflow steps обычно в answer)
        val = item.get("answer") if item.get("answer") is not None else item.get("hint", "")
        keywords = item.get("keywords") or []
        title = _title_of(item, "Без названия")
        candidates.append({
            "type": item_type,
            "title": title,
            "value": val,
            "keywords": keywords,
            "_raw": item
        })

    for it in nav:
        add_candidate(it, "navigation")
    for r in rules:
        if not isinstance(r, dict):
            continue
        add_candidate(r, "rules")

    scored = []
    for cand in candidates:
        best_kw_score = 0.0
        for kw in cand.get("keywords", []) or []:
            s = _score_for_keyword_match(q, kw)
            if s > best_kw_score:
                best_kw_score = s
        if best_kw_score == 0.0:
            best_kw_score = max(
                best_kw_score,
                _token_overlap_score(q, cand.get("title", "")) * 0.8,
                _token_overlap_score(q, str(cand.get("value", ""))) * 0.7
            )
        boost = 1.0
        if cand.get("type") == "navigation":
            boost += 0.20
        try:
            if isinstance(cand.get("value"), dict) and "steps" in cand.get("value"):
                boost += 0.15
        except Exception:
            pass
        final_score = best_kw_score * boost
        if final_score > 0:
            scored.append({"cand": cand, "score": final_score, "kw_score": best_kw_score})

    scored.sort(key=lambda x: x["score"], reverse=True)

    if DEBUG_RANKING:
        print("DEBUG scored (top 8):")
        for s in scored[:8]:
            title = (s['cand']['title'] or "")[:80]
            print(f"  {title:80} | type={s['cand']['type']:10} | score={s['score']:.3f} | kw_score={s['kw_score']:.3f}")

    if scored:
        top = scored[0]
        threshold = 0.45
        if top["score"] >= threshold:
            if len(scored) == 1 or (top["score"] - scored[1]["score"]) >= 0.08:
                c = top["cand"]
                return [{"type": c["type"], "title": c["title"], "value": c["value"]}]
        options = []
        used = set()
        for s in scored[:6]:
            c = s["cand"]
            key = (c["type"], str(c["value"]))
            if key in used:
                continue
            used.add(key)
            options.append({"type": c["type"], "title": c["title"], "value": c["value"]})
        if options:
            return options

    # семантический fallback
    sem = []
    try:
        sem = _semantic_match_with_embeddings(q, device, top_k=3)
    except Exception:
        sem = []
    if not sem:
        try:
            sem = _semantic_match_with_chat(q, device, top_k=3)
        except Exception:
            sem = []
    final = []
    seen = set()
    for r in sem:
        key = (r.get("type"), str(r.get("value")))
        if key in seen:
            continue
        seen.add(key)
        final.append({"type": r.get("type"), "title": r.get("title"), "value": r.get("value")})
    return final


# парсинг выбора опции
def parse_choice(text: str, options: List[Dict]) -> Optional[int]:
    if not text or not options:
        return None
    t = text.strip().lower()
    map_num = {
        "1": 0, "первое": 0, "первый": 0,
        "2": 1, "второе": 1, "второй": 1,
        "3": 2, "третье": 2, "третий": 2,
        "4": 3, "четвёртое": 3, "четвертое": 3, "четвёртый": 3, "четвертый": 3,
        "5": 4, "пятое": 4, "пятый": 4
    }
    if t in map_num and map_num[t] < len(options):
        return map_num[t]

    if "правил" in t or "правила" in t or "услов" in t or "можно" in t or "запрещ" in t:
        for i, opt in enumerate(options):
            if opt.get("type") == "rules":
                return i
    if "раздел" in t or "где" in t or "куда" in t or "найти" in t or "странице" in t or "зайти" in t:
        for i, opt in enumerate(options):
            if opt.get("type") == "navigation":
                return i

    for i, opt in enumerate(options):
        title = (opt.get("title") or "").lower()
        if title:
            for word in title.split():
                if word and word in t:
                    return i

    for token in t.replace(")", " ").replace(".", " ").split():
        if token.isdigit():
            idx = int(token) - 1
            if 0 <= idx < len(options):
                return idx

    return None


OFF_TOPIC_KEYWORDS = [
    "python", "код", "программа", "function", "array", "массив", "счётчик", "счетчик", "counter",
    "for", "while", "list", "class", "javascript", "java", "c++", "go", "rust", "sql", "база данных"
]

def is_off_topic(question: str) -> bool:
    q = (question or "").lower()
    for kw in OFF_TOPIC_KEYWORDS:
        if kw in q:
            return True
    return False


def humanize_answer(short_answer: str, user_question: str) -> str:
    if not openai_client:
        return short_answer
    try:
        resp = openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"Сформулируй коротко и по-человечески ответ на вопрос: {user_question}\n\nИнформация:\n{short_answer}"}
            ],
            temperature=0.2,
        )
        if resp and getattr(resp, "choices", None):
            choice0 = resp.choices[0]
            if hasattr(choice0, "message") and isinstance(choice0.message, dict):
                return choice0.message.get("content") or short_answer
            if hasattr(choice0, "message") and hasattr(choice0.message, "get"):
                return choice0.message.get("content") or short_answer
            if hasattr(choice0, "text"):
                return choice0.text or short_answer
        return short_answer
    except Exception:
        return short_answer


# центральная функция ask_ai (не менял контракт)
async def ask_ai(user_id: int, question: str) -> Any:
    q = (question or "").strip()

    # обработка payload device:
    if q.startswith("device:"):
        _, val = q.split(":", 1)
        val = val.strip()
        if val in ("mobile", "desktop"):
            sessions.set_device(user_id, val)
            user_device[user_id] = val
            sessions.add_history(user_id, "assistant", f"device_set_{val}")
            return "Отлично! Слушаю вас внимательно, какой будет вопрос?"

    # приветствие + выбор устройства
    if not sessions.was_seen(user_id):
        sessions.mark_seen(user_id)
        sessions.add_history(user_id, "assistant", "greet_asked_device")
        return {
            "text": "Здравствуйте! Выберите, через какое устройство вы пользуетесь:",
            "buttons": [
                {"text": "Смартфон", "data": "device:mobile"},
                {"text": "Компьютер", "data": "device:desktop"}
            ]
        }

    # device selection
    if not sessions.has_device(user_id):
        t = q.lower()
        if any(x in t for x in ("смартфон", "телефон", "mobile", "мобил")):
            sessions.set_device(user_id, "mobile")
            user_device[user_id] = "mobile"
            sessions.add_history(user_id, "assistant", "device_set_mobile")
            return "Отлично! Слушаю вас внимательно, какой будет вопрос?"
        if any(x in t for x in ("компьютер", "пк", "desktop", "ноут")):
            sessions.set_device(user_id, "desktop")
            user_device[user_id] = "desktop"
            sessions.add_history(user_id, "assistant", "device_set_desktop")
            return "Отлично! Слушаю вас внимательно, какой будет вопрос?"
        return "Пожалуйста, выберите устройство: «смартфон» или «компьютер»."

    # ожидающий выбор
    pending = sessions.get_pending(user_id)
    if pending:
        idx = parse_choice(q, pending)
        if idx is None:
            return "Пожалуйста, выберите вариант: напишите номер (1, 2, ...) или напишите фразу полностью."
        selected = pending[idx]
        sessions.clear_pending(user_id)
        answer_text = selected.get("value") or "Информация отсутствует."
        # если value — dict со steps, сформируем шаги
        if isinstance(answer_text, dict) and "steps" in answer_text:
            lines = [f"Чтобы {answer_text.get('title')}, выполните следующие шаги:"]
            for i, step in enumerate(answer_text["steps"], start=1):
                lines.append(f"{i}. {step}.")
            return "\n".join(lines)
        return humanize_answer(answer_text, question)

    # off-topic
    if is_off_topic(q):
        return "Извините, я могу отвечать только по вопросам, связанным с работой сайта. Обратитесь по вопросам сайта."

    # основной поиск
    device = sessions.get_device(user_id) or "desktop"
    matches = search_matches(q, device)

    if not matches:
        return "Мне не удалось найти точный ответ в базе по этому вопросу. Пожалуйста, уточните, о чём именно идёт речь на сайте."

    if len(matches) == 1:
        data = matches[0].get("value")
        if isinstance(data, dict) and "steps" in data:
            lines = [f"Чтобы {data.get('title')}, выполните следующие шаги:"]
            for i, step in enumerate(data["steps"], start=1):
                lines.append(f"{i}. {step}.")
            return "\n".join(lines)
        if isinstance(data, str) and data.strip():
            return humanize_answer(data, question)
        return "Информация по этому вопросу временно недоступна."

    # несколько вариантов -> сохраняем pending и предлагаем выбор
    sessions.set_pending(user_id, matches)
    lines = ["Я нашёл несколько вариантов. Что вы имеете в виду:"]
    for i, m in enumerate(matches, start=1):
        label = "Правила" if m.get("type") == "rules" else "Раздел"
        title = m.get("title") or "(без названия)"
        lines.append(f"{i}) {title} ({label})")
    lines.append("\nНапишите номер варианта (например, 1 или 2), либо напишите фразу полностью.")
    return "\n".join(lines)
